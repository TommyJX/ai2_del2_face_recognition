{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model1 = load_model('../models/best_age_model.keras')\n",
    "model2 = load_model('../models/best_emotion_model.keras')\n",
    "model3 = load_model('../models/best_gender_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained face detector (e.g., Haar cascades)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender label dictionary\n",
    "gender_dict = {0: 'Male', 1: 'Female'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IDEAL_FACE_SIZE = 128  # Ideal size of the face in pixels\n",
    "TOLERANCE = 30  # Tolerance for face size (can be adjusted)\n",
    "STABLE_TIME_REQUIRED = 5  # Seconds required to be stable in the green square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to track timing\n",
    "start_time = None\n",
    "predicted = False\n",
    "final_pred_gender = None\n",
    "final_pred_age = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    if len(faces) > 0:\n",
    "        (x, y, w, h) = faces[0]  # Assuming the first detected face is the target\n",
    "        face = gray[y:y+h, x:x+w]  # Crop the face\n",
    "    else:\n",
    "        face = gray  # Use the whole frame if no face is detected\n",
    "    \n",
    "    face = cv2.resize(face, (128, 128))  # Resize to model input size\n",
    "    face = face / 255.0  # Normalize\n",
    "    face = np.expand_dims(face, axis=-1)  # Add channel dimension\n",
    "    face = np.expand_dims(face, axis=0)  # Add batch dimension\n",
    "    \n",
    "    return face, (x, y, w, h) if len(faces) > 0 else None\n",
    "\n",
    "def predict_gender_age(img):\n",
    "    processed_img, face_bbox = preprocess_image(img)\n",
    "    pred = model.predict(processed_img)\n",
    "    \n",
    "    pred_gender_prob = pred[0][0].item()  # Extract scalar using item()\n",
    "    pred_gender = gender_dict[round(pred_gender_prob)]  # Round to nearest gender\n",
    "    \n",
    "    pred_age_value = pred[1][0].item()  # Extract scalar using item()\n",
    "\n",
    "    # Determine dynamic range for age prediction\n",
    "    range_width = max(2, int(0.1 * pred_age_value))  # 10% of the predicted age, with a minimum range of 2\n",
    "    pred_age_lower = max(0, round(pred_age_value - range_width))  # Lower bound\n",
    "    pred_age_upper = round(pred_age_value + range_width)  # Upper bound\n",
    "    \n",
    "    return pred_gender, (pred_age_lower, pred_age_upper), face_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    pred_gender, (pred_age_lower, pred_age_upper), face_bbox = predict_gender_age(frame)\n",
    "    \n",
    "    # Define the ideal square frame size and position\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    square_size = 250  # Size of the square in pixels\n",
    "    square_x = (frame_width - square_size) // 2\n",
    "    square_y = (frame_height - square_size) // 2\n",
    "    \n",
    "    # Determine color of the square frame\n",
    "    color = (0, 0, 255)  # Default to red (too far or too close)\n",
    "    if face_bbox is not None:\n",
    "        _, _, w, h = face_bbox\n",
    "        face_size = max(w, h)\n",
    "        \n",
    "        if IDEAL_FACE_SIZE - TOLERANCE <= face_size <= IDEAL_FACE_SIZE + TOLERANCE:\n",
    "            color = (0, 255, 0)  # Green (perfect distance)\n",
    "            if start_time is None:\n",
    "                start_time = time.time()  # Start timing when the face is first in the green square\n",
    "            else:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                if elapsed_time >= STABLE_TIME_REQUIRED:\n",
    "                    predicted = True\n",
    "                    final_pred_gender = pred_gender\n",
    "                    final_pred_age = f'{pred_age_lower}-{pred_age_upper}'\n",
    "        else:\n",
    "            start_time = None  # Reset timing if the face leaves the green square\n",
    "    else:\n",
    "        start_time = None  # Reset timing if no face is detected\n",
    "    \n",
    "    # Draw the square frame\n",
    "    cv2.rectangle(frame, (square_x, square_y), (square_x + square_size, square_y + square_size), color, 2)\n",
    "    \n",
    "    # Display real-time predictions or final predictions\n",
    "    font_scale = 0.8  # Adjust font scale to make text smaller\n",
    "    font_thickness = 2\n",
    "    text_color = (255, 255, 255)  # White color for the text\n",
    "\n",
    "    if predicted:\n",
    "        cv2.putText(frame, f'Gender: {final_pred_gender}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, font_thickness)\n",
    "        cv2.putText(frame, f'Age: {final_pred_age}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, font_thickness)\n",
    "    else:\n",
    "        cv2.putText(frame, f'Gender: {pred_gender}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, font_thickness)\n",
    "        cv2.putText(frame, f'Age: {pred_age_lower}-{pred_age_upper}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, font_thickness)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Gender and Age Prediction', frame)\n",
    "    \n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
